"""Initial migration: create all tables

Revision ID: 1d1b940188ef
Revises: 
Create Date: 2025-10-04 14:21:30.166086

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '1d1b940188ef'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_mapping_history_created_at', table_name='mapping_history')
    op.drop_index('idx_mapping_history_item_id', table_name='mapping_history')
    op.drop_index('idx_mapping_history_order_id', table_name='mapping_history')
    op.drop_index('idx_mapping_history_order_version', table_name='mapping_history')
    op.drop_table('mapping_history')
    op.drop_table('db_files')
    op.drop_index('ix_system_settings_setting_id', table_name='system_settings')
    op.drop_table('system_settings')
    op.alter_column('api_usage', 'api_call_timestamp',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('api_usage', 'model',
               existing_type=sa.VARCHAR(length=255),
               nullable=False)
    op.drop_index('idx_api_usage_job', table_name='api_usage')
    op.drop_index('idx_api_usage_job_id', table_name='api_usage')
    op.drop_index('idx_api_usage_timestamp', table_name='api_usage')
    op.create_index(op.f('ix_api_usage_usage_id'), 'api_usage', ['usage_id'], unique=False)
    op.drop_constraint('api_usage_job_id_fkey', 'api_usage', type_='foreignkey')
    op.create_foreign_key(None, 'api_usage', 'processing_jobs', ['job_id'], ['job_id'])
    op.drop_table_comment(
        'api_usage',
        existing_comment='Tracks API usage metrics for token consumption analytics',
        schema=None
    )
    op.alter_column('batch_jobs', 'company_id',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('batch_jobs', 'upload_description',
               existing_type=sa.VARCHAR(length=255),
               nullable=True,
               comment='Description of uploaded files (filename or summary)',
               existing_server_default=sa.text("''::character varying"))
    op.alter_column('batch_jobs', 's3_upload_path',
               existing_type=sa.VARCHAR(length=255),
               nullable=True,
               comment='S3 path to uploaded files')
    op.alter_column('batch_jobs', 'upload_type',
               existing_type=postgresql.ENUM('single_file', 'multiple_files', 'zip_file', 'mixed', name='upload_type_enum'),
               type_=sa.Enum('single_file', 'multiple_files', 'zip_file', 'mixed', name='uploadtype'),
               comment='Type of upload batch',
               existing_nullable=False,
               existing_server_default=sa.text("'single_file'::upload_type_enum"))
    op.alter_column('batch_jobs', 'original_file_names',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               comment='Array of original uploaded filenames',
               existing_nullable=True)
    op.alter_column('batch_jobs', 'file_count',
               existing_type=sa.INTEGER(),
               comment='Total number of files in this batch',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('batch_jobs', 'total_files',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('batch_jobs', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_batch_jobs_company_id', table_name='batch_jobs')
    op.drop_index('idx_batch_jobs_created_at', table_name='batch_jobs')
    op.drop_index('idx_batch_jobs_status', table_name='batch_jobs')
    op.drop_column('batch_jobs', 'successful_files')
    op.drop_column('batch_jobs', 'failed_files')
    op.alter_column('companies', 'company_name',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=100),
               existing_nullable=False)
    op.alter_column('company_document_configs', 'storage_type',
               existing_type=postgresql.ENUM('local', 's3', name='storage_type'),
               type_=sa.Enum('local', 's3', name='storagetype'),
               existing_comment='Storage backend type for prompts and schemas',
               existing_nullable=False,
               existing_server_default=sa.text("'local'::storage_type"))
    op.alter_column('company_document_configs', 'default_mapping_keys',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               comment='Default mapping keys for auto-mapping [key1, key2, key3]',
               existing_nullable=True,
               existing_server_default=sa.text("'[]'::jsonb"))
    op.alter_column('company_document_configs', 'auto_mapping_enabled',
               existing_type=sa.BOOLEAN(),
               nullable=True,
               comment='Whether to enable auto-mapping for this document type',
               existing_server_default=sa.text('false'))
    op.alter_column('company_document_configs', 'cross_field_mappings',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               comment='Cross-field mappings for semantic field mapping {"ocr_field": "mapping_field"}',
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_index('idx_company_document_configs_default_mapping_keys', table_name='company_document_configs', postgresql_using='gin')
    op.drop_index('idx_storage_type', table_name='company_document_configs')
    op.drop_constraint('company_document_configs_doc_type_id_fkey', 'company_document_configs', type_='foreignkey')
    op.drop_constraint('company_document_configs_company_id_fkey', 'company_document_configs', type_='foreignkey')
    op.create_foreign_key(None, 'company_document_configs', 'companies', ['company_id'], ['company_id'])
    op.create_foreign_key(None, 'company_document_configs', 'document_types', ['doc_type_id'], ['doc_type_id'])
    op.drop_column('company_document_configs', 'mapping_suggestions_config')
    op.drop_constraint('document_files_job_id_fkey', 'document_files', type_='foreignkey')
    op.drop_constraint('document_files_file_id_fkey', 'document_files', type_='foreignkey')
    op.create_foreign_key(None, 'document_files', 'processing_jobs', ['job_id'], ['job_id'])
    op.create_foreign_key(None, 'document_files', 'files', ['file_id'], ['file_id'])
    op.alter_column('document_types', 'type_name',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=100),
               existing_nullable=False)
    op.alter_column('document_types', 'type_code',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=50),
               existing_nullable=False)
    op.drop_column('document_types', 's3_schema_path')
    op.drop_column('document_types', 's3_prompt_path')
    op.alter_column('files', 'file_path',
               existing_type=sa.VARCHAR(length=512),
               type_=sa.String(length=255),
               existing_nullable=False)
    op.alter_column('files', 'mime_type',
               existing_type=sa.VARCHAR(length=100),
               type_=sa.String(length=255),
               existing_nullable=True)
    op.alter_column('files', 's3_key',
               existing_type=sa.VARCHAR(length=512),
               type_=sa.String(length=255),
               existing_nullable=True)
    op.create_unique_constraint(None, 'files', ['file_path'])
    op.alter_column('ocr_order_items', 'item_name',
               existing_type=sa.VARCHAR(length=255),
               comment='User-friendly name for this item',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'status',
               existing_type=postgresql.ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', name='order_item_status_enum'),
               type_=sa.Enum('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', name='orderitemstatus'),
               existing_nullable=False,
               existing_server_default=sa.text("'PENDING'::order_item_status_enum"))
    op.alter_column('ocr_order_items', 'file_count',
               existing_type=sa.INTEGER(),
               comment='Number of files in this item',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_order_items', 'ocr_result_json_path',
               existing_type=sa.VARCHAR(length=500),
               comment='S3 path to OCR result JSON file',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'ocr_result_csv_path',
               existing_type=sa.VARCHAR(length=500),
               comment='S3 path to OCR result CSV file',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'mapping_keys',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Selected mapping keys for this item (up to 3 keys)',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ocr_order_items', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_ocr_order_items_company_doc_type', table_name='ocr_order_items')
    op.drop_index('idx_ocr_order_items_order_id', table_name='ocr_order_items')
    op.drop_index('idx_ocr_order_items_status', table_name='ocr_order_items')
    op.alter_column('ocr_orders', 'order_name',
               existing_type=sa.VARCHAR(length=255),
               comment='User-friendly name for the order',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'status',
               existing_type=postgresql.ENUM('DRAFT', 'PROCESSING', 'OCR_COMPLETED', 'MAPPING', 'COMPLETED', 'FAILED', 'LOCKED', name='order_status_enum'),
               type_=sa.Enum('DRAFT', 'PROCESSING', 'OCR_COMPLETED', 'MAPPING', 'COMPLETED', 'FAILED', 'LOCKED', name='orderstatus'),
               comment='Current status of the order',
               existing_nullable=False,
               existing_server_default=sa.text("'DRAFT'::order_status_enum"))
    op.alter_column('ocr_orders', 'mapping_file_path',
               existing_type=sa.VARCHAR(length=500),
               comment='S3 path to uploaded mapping file (Excel/CSV)',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'mapping_keys',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               comment='Array of 1-3 mapping keys selected by user [key1, key2, key3]',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'final_report_paths',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               comment='Paths to final consolidated reports (NetSuite CSV, Excel reports)',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'total_items',
               existing_type=sa.INTEGER(),
               comment='Total number of order items',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_orders', 'completed_items',
               existing_type=sa.INTEGER(),
               comment='Number of completed order items',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_orders', 'failed_items',
               existing_type=sa.INTEGER(),
               comment='Number of failed order items',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_orders', 'error_message',
               existing_type=sa.TEXT(),
               comment='Error message if order processing fails',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ocr_orders', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_ocr_orders_created_at', table_name='ocr_orders')
    op.drop_index('idx_ocr_orders_status', table_name='ocr_orders')
    op.alter_column('order_item_files', 'upload_order',
               existing_type=sa.INTEGER(),
               comment='Order in which file was uploaded to this item',
               existing_nullable=True)
    op.alter_column('order_item_files', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index('idx_order_item_files_item_id', table_name='order_item_files')
    op.alter_column('processing_jobs', 's3_pdf_path',
               existing_type=sa.VARCHAR(length=512),
               type_=sa.String(length=255),
               existing_nullable=True)
    op.alter_column('processing_jobs', 'status',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=20),
               existing_nullable=False)
    op.drop_index('idx_jobs_company_doctype', table_name='processing_jobs')
    op.drop_index('idx_processing_jobs_batch_id', table_name='processing_jobs')
    op.drop_index('idx_processing_jobs_company_id', table_name='processing_jobs')
    op.drop_index('idx_processing_jobs_created_at', table_name='processing_jobs')
    op.drop_index('idx_processing_jobs_doc_type_id', table_name='processing_jobs')
    op.drop_index('idx_processing_jobs_status', table_name='processing_jobs')
    op.drop_index('idx_processing_jobs_uploader', table_name='processing_jobs')
    op.drop_constraint('fk_processing_jobs_department_id', 'processing_jobs', type_='foreignkey')
    op.drop_constraint('processing_jobs_config_id_fkey', 'processing_jobs', type_='foreignkey')
    op.drop_constraint('processing_jobs_uploader_user_id_fkey', 'processing_jobs', type_='foreignkey')
    op.drop_constraint('processing_jobs_doc_type_id_fkey', 'processing_jobs', type_='foreignkey')
    op.create_foreign_key(None, 'processing_jobs', 'document_types', ['doc_type_id'], ['doc_type_id'])
    op.create_foreign_key(None, 'processing_jobs', 'batch_jobs', ['batch_id'], ['batch_id'])
    op.drop_column('processing_jobs', 'config_id')
    op.drop_column('processing_jobs', 'uploader_user_id')
    op.drop_column('processing_jobs', 's3_excel_path')
    op.drop_column('processing_jobs', 'department_id')
    op.drop_column('processing_jobs', 's3_json_path')
    op.alter_column('users', 'cognito_sub',
               existing_type=sa.UUID(),
               type_=sa.String(length=36),
               nullable=False)
    op.drop_index('idx_users_department', table_name='users')
    op.drop_column('users', 'password')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('users', sa.Column('password', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
    op.create_index('idx_users_department', 'users', ['department_id'], unique=False)
    op.alter_column('users', 'cognito_sub',
               existing_type=sa.String(length=36),
               type_=sa.UUID(),
               nullable=True)
    op.add_column('processing_jobs', sa.Column('s3_json_path', sa.VARCHAR(length=512), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('department_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('s3_excel_path', sa.VARCHAR(length=512), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('uploader_user_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('processing_jobs', sa.Column('config_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'processing_jobs', type_='foreignkey')
    op.drop_constraint(None, 'processing_jobs', type_='foreignkey')
    op.create_foreign_key('processing_jobs_doc_type_id_fkey', 'processing_jobs', 'document_types', ['doc_type_id'], ['doc_type_id'], ondelete='RESTRICT')
    op.create_foreign_key('processing_jobs_uploader_user_id_fkey', 'processing_jobs', 'users', ['uploader_user_id'], ['user_id'], ondelete='RESTRICT')
    op.create_foreign_key('processing_jobs_config_id_fkey', 'processing_jobs', 'company_document_configs', ['config_id'], ['config_id'])
    op.create_foreign_key('fk_processing_jobs_department_id', 'processing_jobs', 'departments', ['department_id'], ['department_id'])
    op.create_index('idx_processing_jobs_uploader', 'processing_jobs', ['uploader_user_id'], unique=False)
    op.create_index('idx_processing_jobs_status', 'processing_jobs', ['status'], unique=False)
    op.create_index('idx_processing_jobs_doc_type_id', 'processing_jobs', ['doc_type_id'], unique=False)
    op.create_index('idx_processing_jobs_created_at', 'processing_jobs', ['created_at'], unique=False)
    op.create_index('idx_processing_jobs_company_id', 'processing_jobs', ['company_id'], unique=False)
    op.create_index('idx_processing_jobs_batch_id', 'processing_jobs', ['batch_id'], unique=False)
    op.create_index('idx_jobs_company_doctype', 'processing_jobs', ['company_id', 'doc_type_id'], unique=False)
    op.alter_column('processing_jobs', 'status',
               existing_type=sa.String(length=20),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.alter_column('processing_jobs', 's3_pdf_path',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=512),
               existing_nullable=True)
    op.create_index('idx_order_item_files_item_id', 'order_item_files', ['item_id'], unique=False)
    op.alter_column('order_item_files', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('order_item_files', 'upload_order',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Order in which file was uploaded to this item',
               existing_nullable=True)
    op.create_index('idx_ocr_orders_status', 'ocr_orders', ['status'], unique=False)
    op.create_index('idx_ocr_orders_created_at', 'ocr_orders', ['created_at'], unique=False)
    op.alter_column('ocr_orders', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ocr_orders', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ocr_orders', 'error_message',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Error message if order processing fails',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'failed_items',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of failed order items',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_orders', 'completed_items',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of completed order items',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_orders', 'total_items',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Total number of order items',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_orders', 'final_report_paths',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               comment=None,
               existing_comment='Paths to final consolidated reports (NetSuite CSV, Excel reports)',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'mapping_keys',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               comment=None,
               existing_comment='Array of 1-3 mapping keys selected by user [key1, key2, key3]',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'mapping_file_path',
               existing_type=sa.VARCHAR(length=500),
               comment=None,
               existing_comment='S3 path to uploaded mapping file (Excel/CSV)',
               existing_nullable=True)
    op.alter_column('ocr_orders', 'status',
               existing_type=sa.Enum('DRAFT', 'PROCESSING', 'OCR_COMPLETED', 'MAPPING', 'COMPLETED', 'FAILED', 'LOCKED', name='orderstatus'),
               type_=postgresql.ENUM('DRAFT', 'PROCESSING', 'OCR_COMPLETED', 'MAPPING', 'COMPLETED', 'FAILED', 'LOCKED', name='order_status_enum'),
               comment=None,
               existing_comment='Current status of the order',
               existing_nullable=False,
               existing_server_default=sa.text("'DRAFT'::order_status_enum"))
    op.alter_column('ocr_orders', 'order_name',
               existing_type=sa.VARCHAR(length=255),
               comment=None,
               existing_comment='User-friendly name for the order',
               existing_nullable=True)
    op.create_index('idx_ocr_order_items_status', 'ocr_order_items', ['status'], unique=False)
    op.create_index('idx_ocr_order_items_order_id', 'ocr_order_items', ['order_id'], unique=False)
    op.create_index('idx_ocr_order_items_company_doc_type', 'ocr_order_items', ['company_id', 'doc_type_id'], unique=False)
    op.alter_column('ocr_order_items', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ocr_order_items', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ocr_order_items', 'mapping_keys',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Selected mapping keys for this item (up to 3 keys)',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'ocr_result_csv_path',
               existing_type=sa.VARCHAR(length=500),
               comment=None,
               existing_comment='S3 path to OCR result CSV file',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'ocr_result_json_path',
               existing_type=sa.VARCHAR(length=500),
               comment=None,
               existing_comment='S3 path to OCR result JSON file',
               existing_nullable=True)
    op.alter_column('ocr_order_items', 'file_count',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of files in this item',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('ocr_order_items', 'status',
               existing_type=sa.Enum('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', name='orderitemstatus'),
               type_=postgresql.ENUM('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED', name='order_item_status_enum'),
               existing_nullable=False,
               existing_server_default=sa.text("'PENDING'::order_item_status_enum"))
    op.alter_column('ocr_order_items', 'item_name',
               existing_type=sa.VARCHAR(length=255),
               comment=None,
               existing_comment='User-friendly name for this item',
               existing_nullable=True)
    op.drop_constraint(None, 'files', type_='unique')
    op.alter_column('files', 's3_key',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=512),
               existing_nullable=True)
    op.alter_column('files', 'mime_type',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=100),
               existing_nullable=True)
    op.alter_column('files', 'file_path',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=512),
               existing_nullable=False)
    op.add_column('document_types', sa.Column('s3_prompt_path', sa.VARCHAR(length=512), autoincrement=False, nullable=True))
    op.add_column('document_types', sa.Column('s3_schema_path', sa.VARCHAR(length=512), autoincrement=False, nullable=True))
    op.alter_column('document_types', 'type_code',
               existing_type=sa.String(length=50),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.alter_column('document_types', 'type_name',
               existing_type=sa.String(length=100),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.drop_constraint(None, 'document_files', type_='foreignkey')
    op.drop_constraint(None, 'document_files', type_='foreignkey')
    op.create_foreign_key('document_files_file_id_fkey', 'document_files', 'files', ['file_id'], ['file_id'], ondelete='CASCADE')
    op.create_foreign_key('document_files_job_id_fkey', 'document_files', 'processing_jobs', ['job_id'], ['job_id'], ondelete='CASCADE')
    op.add_column('company_document_configs', sa.Column('mapping_suggestions_config', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'company_document_configs', type_='foreignkey')
    op.drop_constraint(None, 'company_document_configs', type_='foreignkey')
    op.create_foreign_key('company_document_configs_company_id_fkey', 'company_document_configs', 'companies', ['company_id'], ['company_id'], ondelete='CASCADE')
    op.create_foreign_key('company_document_configs_doc_type_id_fkey', 'company_document_configs', 'document_types', ['doc_type_id'], ['doc_type_id'], ondelete='CASCADE')
    op.create_index('idx_storage_type', 'company_document_configs', ['storage_type'], unique=False)
    op.create_index('idx_company_document_configs_default_mapping_keys', 'company_document_configs', ['default_mapping_keys'], unique=False, postgresql_using='gin')
    op.alter_column('company_document_configs', 'cross_field_mappings',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               comment=None,
               existing_comment='Cross-field mappings for semantic field mapping {"ocr_field": "mapping_field"}',
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('company_document_configs', 'auto_mapping_enabled',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               comment=None,
               existing_comment='Whether to enable auto-mapping for this document type',
               existing_server_default=sa.text('false'))
    op.alter_column('company_document_configs', 'default_mapping_keys',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               comment=None,
               existing_comment='Default mapping keys for auto-mapping [key1, key2, key3]',
               existing_nullable=True,
               existing_server_default=sa.text("'[]'::jsonb"))
    op.alter_column('company_document_configs', 'storage_type',
               existing_type=sa.Enum('local', 's3', name='storagetype'),
               type_=postgresql.ENUM('local', 's3', name='storage_type'),
               existing_comment='Storage backend type for prompts and schemas',
               existing_nullable=False,
               existing_server_default=sa.text("'local'::storage_type"))
    op.alter_column('companies', 'company_name',
               existing_type=sa.String(length=100),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.add_column('batch_jobs', sa.Column('failed_files', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True))
    op.add_column('batch_jobs', sa.Column('successful_files', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True))
    op.create_index('idx_batch_jobs_status', 'batch_jobs', ['status'], unique=False)
    op.create_index('idx_batch_jobs_created_at', 'batch_jobs', ['created_at'], unique=False)
    op.create_index('idx_batch_jobs_company_id', 'batch_jobs', ['company_id'], unique=False)
    op.alter_column('batch_jobs', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('batch_jobs', 'total_files',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('batch_jobs', 'file_count',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Total number of files in this batch',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
    op.alter_column('batch_jobs', 'original_file_names',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               comment=None,
               existing_comment='Array of original uploaded filenames',
               existing_nullable=True)
    op.alter_column('batch_jobs', 'upload_type',
               existing_type=sa.Enum('single_file', 'multiple_files', 'zip_file', 'mixed', name='uploadtype'),
               type_=postgresql.ENUM('single_file', 'multiple_files', 'zip_file', 'mixed', name='upload_type_enum'),
               comment=None,
               existing_comment='Type of upload batch',
               existing_nullable=False,
               existing_server_default=sa.text("'single_file'::upload_type_enum"))
    op.alter_column('batch_jobs', 's3_upload_path',
               existing_type=sa.VARCHAR(length=255),
               nullable=False,
               comment=None,
               existing_comment='S3 path to uploaded files')
    op.alter_column('batch_jobs', 'upload_description',
               existing_type=sa.VARCHAR(length=255),
               nullable=False,
               comment=None,
               existing_comment='Description of uploaded files (filename or summary)',
               existing_server_default=sa.text("''::character varying"))
    op.alter_column('batch_jobs', 'company_id',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.create_table_comment(
        'api_usage',
        'Tracks API usage metrics for token consumption analytics',
        existing_comment=None,
        schema=None
    )
    op.drop_constraint(None, 'api_usage', type_='foreignkey')
    op.create_foreign_key('api_usage_job_id_fkey', 'api_usage', 'processing_jobs', ['job_id'], ['job_id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_api_usage_usage_id'), table_name='api_usage')
    op.create_index('idx_api_usage_timestamp', 'api_usage', ['api_call_timestamp'], unique=False)
    op.create_index('idx_api_usage_job_id', 'api_usage', ['job_id'], unique=False)
    op.create_index('idx_api_usage_job', 'api_usage', ['job_id'], unique=False)
    op.alter_column('api_usage', 'model',
               existing_type=sa.VARCHAR(length=255),
               nullable=True)
    op.alter_column('api_usage', 'api_call_timestamp',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.create_table('system_settings',
    sa.Column('setting_id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('key', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('value', sa.VARCHAR(length=1000), autoincrement=False, nullable=False),
    sa.Column('description', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('setting_id', name='system_settings_pkey'),
    sa.UniqueConstraint('key', name='system_settings_key_key')
    )
    op.create_index('ix_system_settings_setting_id', 'system_settings', ['setting_id'], unique=False)
    op.create_table('db_files',
    sa.Column('file_id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('file_path', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('file_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('job_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['job_id'], ['processing_jobs.job_id'], name='db_files_job_id_fkey'),
    sa.PrimaryKeyConstraint('file_id', name='db_files_pkey'),
    sa.UniqueConstraint('file_path', name='db_files_file_path_key')
    )
    op.create_table('mapping_history',
    sa.Column('history_id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('order_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('item_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('mapping_version', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('mapping_keys', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('mapping_config', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('operation_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('operation_reason', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_by', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('mapping_statistics', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('history_id', name='mapping_history_pkey')
    )
    op.create_index('idx_mapping_history_order_version', 'mapping_history', ['order_id', 'mapping_version'], unique=False)
    op.create_index('idx_mapping_history_order_id', 'mapping_history', ['order_id'], unique=False)
    op.create_index('idx_mapping_history_item_id', 'mapping_history', ['item_id'], unique=False)
    op.create_index('idx_mapping_history_created_at', 'mapping_history', [sa.text('created_at DESC')], unique=False)
    # ### end Alembic commands ###
