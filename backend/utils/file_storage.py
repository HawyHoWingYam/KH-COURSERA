import os
import shutil
import logging
from typing import Optional
from pathlib import Path
from datetime import datetime
import tempfile
import uuid

from .s3_storage import get_s3_manager, is_s3_enabled, S3StorageManager

logger = logging.getLogger(__name__)


class FileStorageService:
    """ç»Ÿä¸€çš„æ–‡ä»¶å­˜å‚¨æœåŠ¡ï¼Œæ”¯æŒæœ¬åœ°å­˜å‚¨å’ŒS3å­˜å‚¨"""

    def __init__(self):
        self.s3_manager = get_s3_manager()
        self.use_s3 = is_s3_enabled()
        self.local_upload_dir = "uploads"

        # ç¡®ä¿æœ¬åœ°ä¸Šä¼ ç›®å½•å­˜åœ¨
        if not self.use_s3:
            os.makedirs(self.local_upload_dir, exist_ok=True)

        logger.info(
            f"ğŸ“ æ–‡ä»¶å­˜å‚¨æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨{'S3' if self.use_s3 else 'æœ¬åœ°'}å­˜å‚¨"
        )

    def save_uploaded_file(
        self,
        uploaded_file,
        company_code: str,
        doc_type_code: str,
        job_id: Optional[int] = None,
    ) -> tuple[str, str]:
        """
        ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶

        Args:
            uploaded_file: FastAPI UploadFileå¯¹è±¡
            company_code: å…¬å¸ä»£ç 
            doc_type_code: æ–‡æ¡£ç±»å‹ä»£ç 
            job_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼‰

        Returns:
            tuple[str, str]: (å­˜å‚¨è·¯å¾„, æ˜¾ç¤ºåç§°)
        """
        filename = uploaded_file.filename

        if self.use_s3:
            return self._save_to_s3(
                uploaded_file, company_code, doc_type_code, filename, job_id
            )
        else:
            return self._save_to_local(
                uploaded_file, company_code, doc_type_code, filename, job_id
            )

    def save_order_file(
        self,
        uploaded_file,
        order_id: int,
        item_id: int
    ) -> tuple[str, str]:
        """
        Save uploaded file for OCR Order system
        Uses dedicated order path structure: orders/{order_id}/items/{item_id}/{timestamp}_{filename}

        Args:
            uploaded_file: FastAPI UploadFile object
            order_id: Order ID
            item_id: Order Item ID

        Returns:
            tuple[str, str]: (storage_path, display_name)
        """
        filename = uploaded_file.filename

        if self.use_s3:
            return self._save_order_file_to_s3(uploaded_file, order_id, item_id, filename)
        else:
            return self._save_order_file_to_local(uploaded_file, order_id, item_id, filename)

    def _save_order_file_to_s3(
        self,
        uploaded_file,
        order_id: int,
        item_id: int,
        filename: str
    ) -> tuple[str, str]:
        """Save order file to S3 with dedicated path structure"""
        try:
            # Generate S3 key with order-specific structure
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_id = uuid.uuid4().hex[:8]  # Add uniqueness
            safe_filename = filename.replace(" ", "_")
            s3_key = f"orders/{order_id}/items/{item_id}/{timestamp}_{unique_id}_{safe_filename}"

            # Prepare metadata
            metadata = {
                "order_id": str(order_id),
                "item_id": str(item_id),
                "original_filename": filename,
                "upload_timestamp": timestamp
            }

            # Upload to S3 using S3StorageManager
            success = self.s3_manager.upload_file(
                file_content=uploaded_file.file,
                key=s3_key,
                metadata=metadata
            )

            if not success:
                raise Exception("S3 upload failed")

            # Generate full S3 URI (including upload_prefix since S3StorageManager adds it during upload)
            s3_uri = f"s3://{self.s3_manager.bucket_name}/{self.s3_manager.upload_prefix}{s3_key}"

            logger.info(f"âœ… Order file uploaded to S3: {s3_uri}")
            return s3_uri, filename

        except Exception as e:
            logger.error(f"âŒ Failed to upload order file to S3: {str(e)}")
            raise

    def _save_order_file_to_local(
        self,
        uploaded_file,
        order_id: int,
        item_id: int,
        filename: str
    ) -> tuple[str, str]:
        """Save order file to local storage with dedicated path structure"""
        try:
            # Create directory structure
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_id = uuid.uuid4().hex[:8]
            safe_filename = filename.replace(" ", "_")

            order_dir = os.path.join(self.local_path, "orders", str(order_id), "items", str(item_id))
            os.makedirs(order_dir, exist_ok=True)

            # Generate file path
            local_filename = f"{timestamp}_{unique_id}_{safe_filename}"
            file_path = os.path.join(order_dir, local_filename)

            # Save file
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(uploaded_file.file, buffer)

            logger.info(f"âœ… Order file saved locally: {file_path}")
            return file_path, filename

        except Exception as e:
            logger.error(f"âŒ Failed to save order file locally: {str(e)}")
            raise

    def delete_order_file(self, file_path: str) -> bool:
        """
        Delete order file from storage

        Args:
            file_path: File path (S3 URI or local path)

        Returns:
            bool: True if deletion successful, False otherwise
        """
        try:
            if file_path.startswith('s3://'):
                return self._delete_order_file_from_s3(file_path)
            else:
                return self._delete_order_file_from_local(file_path)
        except Exception as e:
            logger.error(f"âŒ Failed to delete order file {file_path}: {str(e)}")
            return False

    def _delete_order_file_from_s3(self, s3_uri: str) -> bool:
        """Delete order file from S3"""
        try:
            # Parse S3 URI: s3://bucket/key
            s3_parts = s3_uri[5:].split('/', 1)  # Remove 's3://' and split
            if len(s3_parts) != 2:
                logger.error(f"âŒ Invalid S3 URI format: {s3_uri}")
                return False

            bucket_name = s3_parts[0]
            s3_key = s3_parts[1]

            # Delete from S3 using S3StorageManager's boto3 client
            self.s3_manager.s3_client.delete_object(Bucket=bucket_name, Key=s3_key)
            logger.info(f"âœ… Order file deleted from S3: {s3_uri}")
            return True

        except Exception as e:
            logger.error(f"âŒ Failed to delete order file from S3 {s3_uri}: {str(e)}")
            return False

    def _delete_order_file_from_local(self, file_path: str) -> bool:
        """Delete order file from local storage"""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                logger.info(f"âœ… Order file deleted locally: {file_path}")
                return True
            else:
                logger.warning(f"âš ï¸ Order file not found locally: {file_path}")
                return False

        except Exception as e:
            logger.error(f"âŒ Failed to delete order file locally {file_path}: {str(e)}")
            return False

    def save_order_mapping_file(
        self,
        uploaded_file,
        order_id: int
    ) -> tuple[str, str]:
        """
        Save mapping file for OCR Order system
        Uses dedicated path: orders/{order_id}/mapping/{timestamp}_{filename}

        Args:
            uploaded_file: FastAPI UploadFile object
            order_id: Order ID

        Returns:
            tuple[str, str]: (storage_path, display_name)
        """
        filename = uploaded_file.filename

        if self.use_s3:
            return self._save_order_mapping_file_to_s3(uploaded_file, order_id, filename)
        else:
            return self._save_order_mapping_file_to_local(uploaded_file, order_id, filename)

    def _save_order_mapping_file_to_s3(
        self,
        uploaded_file,
        order_id: int,
        filename: str
    ) -> tuple[str, str]:
        """Save order mapping file to S3"""
        try:
            # Generate S3 key for mapping file
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_id = uuid.uuid4().hex[:8]
            safe_filename = filename.replace(" ", "_")
            s3_key = f"orders/{order_id}/mapping/{timestamp}_{unique_id}_{safe_filename}"

            # Prepare metadata
            metadata = {
                "order_id": str(order_id),
                "file_type": "mapping",
                "original_filename": filename,
                "upload_timestamp": timestamp
            }

            # Upload to S3 using S3StorageManager
            success = self.s3_manager.upload_file(
                file_content=uploaded_file.file,
                key=s3_key,
                metadata=metadata
            )

            if not success:
                raise Exception("S3 upload failed")

            # Generate full S3 URI (including upload_prefix since S3StorageManager adds it during upload)
            s3_uri = f"s3://{self.s3_manager.bucket_name}/{self.s3_manager.upload_prefix}{s3_key}"

            logger.info(f"âœ… Order mapping file uploaded to S3: {s3_uri}")
            return s3_uri, filename

        except Exception as e:
            logger.error(f"âŒ Failed to upload order mapping file to S3: {str(e)}")
            raise

    def _save_order_mapping_file_to_local(
        self,
        uploaded_file,
        order_id: int,
        filename: str
    ) -> tuple[str, str]:
        """Save order mapping file to local storage"""
        try:
            # Create directory structure
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_id = uuid.uuid4().hex[:8]
            safe_filename = filename.replace(" ", "_")

            mapping_dir = os.path.join(self.local_path, "orders", str(order_id), "mapping")
            os.makedirs(mapping_dir, exist_ok=True)

            # Generate file path
            local_filename = f"{timestamp}_{unique_id}_{safe_filename}"
            file_path = os.path.join(mapping_dir, local_filename)

            # Save file
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(uploaded_file.file, buffer)

            logger.info(f"âœ… Order mapping file saved locally: {file_path}")
            return file_path, filename

        except Exception as e:
            logger.error(f"âŒ Failed to save order mapping file locally: {str(e)}")
            raise

    def _save_to_s3(
        self,
        uploaded_file,
        company_code: str,
        doc_type_code: str,
        filename: str,
        job_id: Optional[int] = None,
    ) -> tuple[str, str]:
        """ä¿å­˜æ–‡ä»¶åˆ°S3"""
        try:
            # ç”ŸæˆS3é”®å
            s3_key = S3StorageManager.generate_file_key(
                company_code, doc_type_code, filename, job_id
            )

            # å‡†å¤‡å…ƒæ•°æ®
            metadata = {
                "company_code": company_code,
                "doc_type_code": doc_type_code,
                "original_filename": filename,
                "upload_time": datetime.now().isoformat(),
            }

            if job_id:
                metadata["job_id"] = str(job_id)

            # ä¸Šä¼ åˆ°S3
            success = self.s3_manager.upload_file(
                uploaded_file.file,
                s3_key,
                content_type=uploaded_file.content_type,
                metadata=metadata,
            )

            if success:
                logger.info(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ åˆ°S3ï¼š{s3_key}")
                return f"s3://{self.s3_manager.bucket_name}/{s3_key}", filename
            else:
                raise Exception("S3ä¸Šä¼ å¤±è´¥")

        except Exception as e:
            logger.error(f"âŒ S3æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼š{e}")
            # å›é€€åˆ°æœ¬åœ°å­˜å‚¨
            logger.info("ğŸ”„ å›é€€åˆ°æœ¬åœ°å­˜å‚¨")
            return self._save_to_local(
                uploaded_file, company_code, doc_type_code, filename, job_id
            )

    def _save_to_local(
        self,
        uploaded_file,
        company_code: str,
        doc_type_code: str,
        filename: str,
        job_id: Optional[int] = None,
    ) -> tuple[str, str]:
        """ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°"""
        try:
            # æ„å»ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
            if job_id:
                local_dir = os.path.join(
                    self.local_upload_dir, company_code, doc_type_code, "jobs"
                )
            else:
                local_dir = os.path.join(
                    self.local_upload_dir, company_code, doc_type_code
                )

            os.makedirs(local_dir, exist_ok=True)

            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åé¿å…å†²çª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            unique_id = str(uuid.uuid4())[:8]
            safe_filename = "".join(
                c for c in filename if c.isalnum() or c in (" ", "-", "_", ".")
            ).rstrip()
            unique_filename = f"{timestamp}_{unique_id}_{safe_filename}"

            file_path = os.path.join(local_dir, unique_filename)

            # ä¿å­˜æ–‡ä»¶
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(uploaded_file.file, buffer)

            logger.info(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°ï¼š{file_path}")
            return file_path, filename

        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")
            raise

    def read_file(self, file_path: str) -> Optional[bytes]:
        """
        è¯»å–æ–‡ä»¶å†…å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–S3 URLï¼‰

        Returns:
            Optional[bytes]: æ–‡ä»¶å†…å®¹
        """
        if file_path.startswith("s3://"):
            return self._read_from_s3(file_path)
        else:
            return self._read_from_local(file_path)

    def _read_from_s3(self, s3_url: str) -> Optional[bytes]:
        """ä»S3è¯»å–æ–‡ä»¶"""
        try:
            if self.s3_manager:
                return self.s3_manager.download_file_by_stored_path(s3_url)
            else:
                logger.error("âŒ S3ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return None
        except Exception as e:
            logger.error(f"âŒ ä»S3è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return None

    def _read_from_local(self, file_path: str) -> Optional[bytes]:
        """ä»æœ¬åœ°è¯»å–æ–‡ä»¶"""
        try:
            if os.path.exists(file_path):
                with open(file_path, "rb") as f:
                    return f.read()
            else:
                logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
                return None
        except Exception as e:
            logger.error(f"âŒ ä»æœ¬åœ°è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return None

    def download_file(self, file_path: str) -> Optional[bytes]:
        """
        ä¸‹è½½æ–‡ä»¶å†…å®¹ï¼ˆread_fileçš„åˆ«åï¼Œç”¨äºå…¼å®¹æ€§ï¼‰
        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–S3 URLï¼‰
        Returns:
            Optional[bytes]: æ–‡ä»¶å†…å®¹
        """
        return self.read_file(file_path)

    def delete_file(self, file_path: str) -> bool:
        """
        åˆ é™¤æ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–S3 URLï¼‰

        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        if file_path.startswith("s3://"):
            return self._delete_from_s3(file_path)
        else:
            return self._delete_from_local(file_path)

    def _delete_from_s3(self, s3_url: str) -> bool:
        """ä»S3åˆ é™¤æ–‡ä»¶ï¼Œæ”¯æŒS3 URIå’Œç›¸å¯¹è·¯å¾„"""
        try:
            if not self.s3_manager:
                logger.error("âŒ S3ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return False

            # ä½¿ç”¨æ–°çš„delete_file_by_stored_pathæ–¹æ³•å¤„ç†S3 URIå’Œç›¸å¯¹è·¯å¾„
            # è¿™ä¸ªæ–¹æ³•èƒ½å¤Ÿæ­£ç¡®å¤„ç†ä¸¤ç§æ ¼å¼
            return self.s3_manager.delete_file_by_stored_path(s3_url)

        except Exception as e:
            logger.error(f"âŒ ä»S3åˆ é™¤æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return False

    def _delete_from_local(self, file_path: str) -> bool:
        """ä»æœ¬åœ°åˆ é™¤æ–‡ä»¶"""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                logger.info(f"âœ… æœ¬åœ°æ–‡ä»¶åˆ é™¤æˆåŠŸï¼š{file_path}")
                return True
            else:
                logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤ï¼š{file_path}")
                return True
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶åˆ é™¤å¤±è´¥ï¼š{e}")
            return False

    def file_exists(self, file_path: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–S3 URLï¼‰

        Returns:
            bool: æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        """
        if file_path.startswith("s3://"):
            return self._s3_file_exists(file_path)
        else:
            return os.path.exists(file_path)

    def _s3_file_exists(self, s3_url: str) -> bool:
        """æ£€æŸ¥S3æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        try:
            # è§£æS3 URL
            s3_url = s3_url[5:]  # ç§»é™¤ 's3://'
            parts = s3_url.split("/", 1)
            if len(parts) != 2:
                return False

            bucket_name, key = parts

            if self.s3_manager and self.s3_manager.bucket_name == bucket_name:
                return self.s3_manager.file_exists(key)
            else:
                return False

        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥S3æ–‡ä»¶å­˜åœ¨æ—¶å‡ºé”™ï¼š{e}")
            return False

    def get_file_size(self, file_path: str) -> int:
        """
        è·å–æ–‡ä»¶å¤§å°

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–S3 URLï¼‰

        Returns:
            int: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        if file_path.startswith("s3://"):
            return self._get_s3_file_size(file_path)
        else:
            try:
                return os.path.getsize(file_path) if os.path.exists(file_path) else 0
            except (OSError, FileNotFoundError, PermissionError):
                return 0

    def _get_s3_file_size(self, s3_url: str) -> int:
        """è·å–S3æ–‡ä»¶å¤§å°"""
        try:
            # è§£æS3 URL
            s3_url = s3_url[5:]  # ç§»é™¤ 's3://'
            parts = s3_url.split("/", 1)
            if len(parts) != 2:
                return 0

            bucket_name, key = parts

            if self.s3_manager and self.s3_manager.bucket_name == bucket_name:
                file_info = self.s3_manager.get_file_info(key)
                return file_info.get("size", 0) if file_info else 0
            else:
                return 0

        except Exception as e:
            logger.error(f"âŒ è·å–S3æ–‡ä»¶å¤§å°å¤±è´¥ï¼š{e}")
            return 0

    def create_temp_file_from_storage(self, file_path: str) -> Optional[str]:
        """
        ä»å­˜å‚¨ä¸­åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆç”¨äºéœ€è¦æœ¬åœ°æ–‡ä»¶è·¯å¾„çš„æ“ä½œï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æœ¬åœ°è·¯å¾„æˆ–S3 URLï¼‰

        Returns:
            Optional[str]: ä¸´æ—¶æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨åéœ€è¦æ‰‹åŠ¨åˆ é™¤
        """
        if not file_path.startswith("s3://"):
            # æœ¬åœ°æ–‡ä»¶ç›´æ¥è¿”å›åŸè·¯å¾„
            return file_path if os.path.exists(file_path) else None

        # S3æ–‡ä»¶éœ€è¦ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
        try:
            content = self.read_file(file_path)
            if content is None:
                return None

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            suffix = Path(file_path).suffix
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp_file:
                temp_file.write(content)
                temp_path = temp_file.name

            logger.info(f"âœ… ä»S3åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼š{temp_path}")
            return temp_path

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return None

    def cleanup_temp_file(self, temp_path: str):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if temp_path and os.path.exists(temp_path) and temp_path.startswith("/tmp"):
                os.remove(temp_path)
                logger.info(f"âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼š{temp_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{e}")


# å…¨å±€æ–‡ä»¶å­˜å‚¨æœåŠ¡å®ä¾‹
_file_storage_service = None


def get_file_storage() -> FileStorageService:
    """è·å–å…¨å±€æ–‡ä»¶å­˜å‚¨æœåŠ¡å®ä¾‹"""
    global _file_storage_service

    if _file_storage_service is None:
        _file_storage_service = FileStorageService()

    return _file_storage_service
