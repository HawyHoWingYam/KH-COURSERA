#!/usr/bin/env python3
"""
æ•°æ®åº“å¥åº·æ£€æŸ¥è„šæœ¬
ç”¨äºéªŒè¯æ•°æ®åº“è¿æ¥å’ŒåŸºæœ¬åŠŸèƒ½
"""

import sys
import logging
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, "/app")

from db.database import get_database_url
from db.models import Company, DocumentType, ProcessingJob, BatchJob

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def check_database_connection(database_url: str) -> bool:
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
        engine = create_engine(database_url)

        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test"))
            row = result.fetchone()
            if row and row[0] == 1:
                logger.info("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
                engine.dispose()
                return True
            else:
                logger.error("âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥")
                engine.dispose()
                return False

    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return False


def check_tables_exist(database_url: str) -> bool:
    """æ£€æŸ¥å¿…è¦çš„è¡¨æ˜¯å¦å­˜åœ¨"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“è¡¨...")
        engine = create_engine(database_url)

        required_tables = [
            "companies",
            "document_types",
            "company_document_configs",
            "processing_jobs",
            "batch_jobs",
            "files",
            "document_files",
            "api_usage",
            "users",
            "departments",
        ]

        with engine.connect() as conn:
            for table in required_tables:
                try:
                    result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
                    count = result.scalar()
                    logger.info(f"âœ… è¡¨ {table}: {count} æ¡è®°å½•")
                except SQLAlchemyError as e:
                    logger.error(f"âŒ è¡¨ {table} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {e}")
                    engine.dispose()
                    return False

        engine.dispose()
        return True

    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥æ•°æ®åº“è¡¨å¤±è´¥: {e}")
        return False


def check_constraints(database_url: str) -> bool:
    """æ£€æŸ¥æ•°æ®åº“çº¦æŸ"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“çº¦æŸ...")
        engine = create_engine(database_url)

        with engine.connect() as conn:
            # æ£€æŸ¥å¤–é”®çº¦æŸ
            constraints_query = """
            SELECT conname, contype 
            FROM pg_constraint 
            WHERE contype IN ('f', 'c')
            ORDER BY conname
            """

            result = conn.execute(text(constraints_query))
            constraints = result.fetchall()

            fk_count = sum(1 for c in constraints if c[1] == "f")
            check_count = sum(1 for c in constraints if c[1] == "c")

            logger.info(f"âœ… å¤–é”®çº¦æŸ: {fk_count} ä¸ª")
            logger.info(f"âœ… æ£€æŸ¥çº¦æŸ: {check_count} ä¸ª")

        engine.dispose()
        return True

    except Exception as e:
        logger.warning(f"âš ï¸ æ£€æŸ¥çº¦æŸå¤±è´¥ (å¯èƒ½æ˜¯éPostgreSQLæ•°æ®åº“): {e}")
        return True  # éå…³é”®é”™è¯¯


def check_indexes(database_url: str) -> bool:
    """æ£€æŸ¥æ•°æ®åº“ç´¢å¼•"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“ç´¢å¼•...")
        engine = create_engine(database_url)

        with engine.connect() as conn:
            # æ£€æŸ¥ç´¢å¼•
            indexes_query = """
            SELECT indexname, tablename 
            FROM pg_indexes 
            WHERE schemaname = 'public'
            ORDER BY tablename, indexname
            """

            result = conn.execute(text(indexes_query))
            indexes = result.fetchall()

            logger.info(f"âœ… æ•°æ®åº“ç´¢å¼•: {len(indexes)} ä¸ª")

            # æ£€æŸ¥å…³é”®ç´¢å¼•
            key_indexes = [
                "idx_processing_jobs_status",
                "idx_processing_jobs_company_id",
                "idx_api_usage_timestamp",
            ]

            existing_indexes = [idx[0] for idx in indexes]
            for key_idx in key_indexes:
                if key_idx in existing_indexes:
                    logger.info(f"âœ… å…³é”®ç´¢å¼•å­˜åœ¨: {key_idx}")
                else:
                    logger.warning(f"âš ï¸ å…³é”®ç´¢å¼•ç¼ºå¤±: {key_idx}")

        engine.dispose()
        return True

    except Exception as e:
        logger.warning(f"âš ï¸ æ£€æŸ¥ç´¢å¼•å¤±è´¥ (å¯èƒ½æ˜¯éPostgreSQLæ•°æ®åº“): {e}")
        return True  # éå…³é”®é”™è¯¯


def check_data_integrity(database_url: str) -> bool:
    """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
        engine = create_engine(database_url)

        from sqlalchemy.orm import sessionmaker

        Session = sessionmaker(bind=engine)
        session = Session()

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬çš„å…¬å¸å’Œæ–‡æ¡£ç±»å‹æ•°æ®
            company_count = session.query(Company).count()
            doc_type_count = session.query(DocumentType).count()

            if company_count == 0:
                logger.warning("âš ï¸ æ²¡æœ‰å…¬å¸æ•°æ®ï¼Œè¯·æ’å…¥åˆå§‹æ•°æ®")
            else:
                logger.info(f"âœ… å…¬å¸æ•°æ®: {company_count} ä¸ª")

            if doc_type_count == 0:
                logger.warning("âš ï¸ æ²¡æœ‰æ–‡æ¡£ç±»å‹æ•°æ®ï¼Œè¯·æ’å…¥åˆå§‹æ•°æ®")
            else:
                logger.info(f"âœ… æ–‡æ¡£ç±»å‹æ•°æ®: {doc_type_count} ä¸ª")

            # æ£€æŸ¥å¤„ç†ä»»åŠ¡ç»Ÿè®¡
            job_count = session.query(ProcessingJob).count()
            batch_count = session.query(BatchJob).count()

            logger.info(f"âœ… å¤„ç†ä»»åŠ¡: {job_count} ä¸ª")
            logger.info(f"âœ… æ‰¹é‡ä»»åŠ¡: {batch_count} ä¸ª")

        finally:
            session.close()

        engine.dispose()
        return True

    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å¤±è´¥: {e}")
        return False


def check_database_performance(database_url: str) -> bool:
    """ç®€å•çš„æ•°æ®åº“æ€§èƒ½æ£€æŸ¥"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“æ€§èƒ½...")
        engine = create_engine(database_url)

        with engine.connect() as conn:
            # æµ‹è¯•ç®€å•æŸ¥è¯¢å“åº”æ—¶é—´
            start_time = time.time()
            conn.execute(text("SELECT COUNT(*) FROM companies"))
            query_time = time.time() - start_time

            if query_time < 1.0:
                logger.info(f"âœ… æŸ¥è¯¢å“åº”æ—¶é—´: {query_time:.3f}s (è‰¯å¥½)")
            elif query_time < 3.0:
                logger.warning(f"âš ï¸ æŸ¥è¯¢å“åº”æ—¶é—´: {query_time:.3f}s (ä¸€èˆ¬)")
            else:
                logger.warning(f"âš ï¸ æŸ¥è¯¢å“åº”æ—¶é—´: {query_time:.3f}s (è¾ƒæ…¢)")

        engine.dispose()
        return True

    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ” å¼€å§‹æ•°æ®åº“å¥åº·æ£€æŸ¥...")

    try:
        # è·å–æ•°æ®åº“URL
        database_url = get_database_url()
        logger.info(
            f"æ•°æ®åº“: {database_url.split('@')[1] if '@' in database_url else 'localhost'}"
        )

        checks = [
            ("æ•°æ®åº“è¿æ¥", check_database_connection),
            ("æ•°æ®åº“è¡¨", check_tables_exist),
            ("æ•°æ®åº“çº¦æŸ", check_constraints),
            ("æ•°æ®åº“ç´¢å¼•", check_indexes),
            ("æ•°æ®å®Œæ•´æ€§", check_data_integrity),
            ("æ•°æ®åº“æ€§èƒ½", check_database_performance),
        ]

        passed_checks = 0
        total_checks = len(checks)

        for check_name, check_func in checks:
            logger.info(f"ğŸ” æ‰§è¡Œæ£€æŸ¥: {check_name}")
            try:
                if check_func(database_url):
                    passed_checks += 1
                    logger.info(f"âœ… {check_name} - é€šè¿‡")
                else:
                    logger.error(f"âŒ {check_name} - å¤±è´¥")
            except Exception as e:
                logger.error(f"âŒ {check_name} - å¼‚å¸¸: {e}")

        # è¾“å‡ºæ€»ç»“
        logger.info("=" * 50)
        logger.info(f"ğŸ¯ å¥åº·æ£€æŸ¥å®Œæˆ: {passed_checks}/{total_checks} é¡¹é€šè¿‡")

        if passed_checks == total_checks:
            logger.info("ğŸ‰ æ•°æ®åº“å¥åº·çŠ¶æ€: ä¼˜ç§€")
            sys.exit(0)
        elif passed_checks >= total_checks * 0.8:
            logger.warning("âš ï¸ æ•°æ®åº“å¥åº·çŠ¶æ€: è‰¯å¥½ (æœ‰è½»å¾®é—®é¢˜)")
            sys.exit(0)
        elif passed_checks >= total_checks * 0.6:
            logger.warning("âš ï¸ æ•°æ®åº“å¥åº·çŠ¶æ€: ä¸€èˆ¬ (éœ€è¦å…³æ³¨)")
            sys.exit(1)
        else:
            logger.error("âŒ æ•°æ®åº“å¥åº·çŠ¶æ€: å·® (éœ€è¦ç«‹å³å¤„ç†)")
            sys.exit(1)

    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
