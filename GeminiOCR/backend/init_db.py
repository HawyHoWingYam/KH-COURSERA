#!/usr/bin/env python3
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
ç”¨äºåˆ›å»ºæ•°æ®åº“è¡¨å’Œæ’å…¥åˆå§‹æ•°æ®
"""

import os
import sys
import logging
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, '/app')

from db.database import get_database_url, Base
from db.models import (
    Department, User, DocumentType, DepartmentDocTypeAccess, 
    Company, CompanyDocumentConfig, File, ProcessingJob, 
    DocumentFile, ApiUsage, BatchJob
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def wait_for_database(database_url: str, max_retries: int = 30, retry_interval: int = 2):
    """ç­‰å¾…æ•°æ®åº“å¯ç”¨"""
    logger.info("ç­‰å¾…æ•°æ®åº“è¿æ¥...")
    
    for attempt in range(max_retries):
        try:
            engine = create_engine(database_url)
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            engine.dispose()
            return True
            
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"æ•°æ®åº“è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                time.sleep(retry_interval)
            else:
                logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                return False
    
    return False

def create_database_tables(database_url: str):
    """åˆ›å»ºæ•°æ®åº“è¡¨"""
    try:
        logger.info("åˆ›å»ºæ•°æ®åº“è¡¨...")
        engine = create_engine(database_url)
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        Base.metadata.create_all(bind=engine)
        logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸ")
        
        engine.dispose()
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥: {e}")
        return False

def add_check_constraints(database_url: str):
    """æ·»åŠ æ£€æŸ¥çº¦æŸ"""
    try:
        logger.info("æ·»åŠ æ•°æ®åº“æ£€æŸ¥çº¦æŸ...")
        engine = create_engine(database_url)
        
        constraints = [
            # ProcessingJob çŠ¶æ€çº¦æŸ
            """
            ALTER TABLE processing_jobs 
            ADD CONSTRAINT check_status 
            CHECK (status IN ('pending', 'processing', 'success', 'failed', 'error'))
            """,
            
            # BatchJob çŠ¶æ€çº¦æŸ
            """
            ALTER TABLE batch_jobs 
            ADD CONSTRAINT check_batch_status 
            CHECK (status IN ('pending', 'processing', 'success', 'failed', 'error'))
            """,
            
            # User è§’è‰²çº¦æŸ
            """
            ALTER TABLE users 
            ADD CONSTRAINT check_user_role 
            CHECK (role IN ('admin', 'user', 'manager'))
            """,
            
            # API Usage çŠ¶æ€çº¦æŸ
            """
            ALTER TABLE api_usage 
            ADD CONSTRAINT check_api_status 
            CHECK (status IN ('success', 'error', 'success_with_fallback', 'timeout', 'rate_limited'))
            """
        ]
        
        with engine.connect() as conn:
            for constraint_sql in constraints:
                try:
                    conn.execute(text(constraint_sql))
                    conn.commit()
                except SQLAlchemyError as e:
                    # å¦‚æœçº¦æŸå·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                    if "already exists" in str(e) or "duplicate key" in str(e):
                        logger.info(f"çº¦æŸå·²å­˜åœ¨ï¼Œè·³è¿‡...")
                        continue
                    else:
                        logger.warning(f"æ·»åŠ çº¦æŸå¤±è´¥: {e}")
        
        logger.info("âœ… æ•°æ®åº“çº¦æŸæ·»åŠ å®Œæˆ")
        engine.dispose()
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ·»åŠ æ•°æ®åº“çº¦æŸå¤±è´¥: {e}")
        return False

def create_indexes(database_url: str):
    """åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½"""
    try:
        logger.info("åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
        engine = create_engine(database_url)
        
        indexes = [
            # ProcessingJob ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_processing_jobs_status ON processing_jobs(status)",
            "CREATE INDEX IF NOT EXISTS idx_processing_jobs_company_id ON processing_jobs(company_id)",
            "CREATE INDEX IF NOT EXISTS idx_processing_jobs_doc_type_id ON processing_jobs(doc_type_id)",
            "CREATE INDEX IF NOT EXISTS idx_processing_jobs_created_at ON processing_jobs(created_at)",
            
            # BatchJob ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_batch_jobs_status ON batch_jobs(status)",
            "CREATE INDEX IF NOT EXISTS idx_batch_jobs_company_id ON batch_jobs(company_id)",
            "CREATE INDEX IF NOT EXISTS idx_batch_jobs_created_at ON batch_jobs(created_at)",
            
            # ApiUsage ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_api_usage_timestamp ON api_usage(api_call_timestamp)",
            "CREATE INDEX IF NOT EXISTS idx_api_usage_job_id ON api_usage(job_id)",
            
            # å¤åˆç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_jobs_company_doctype ON processing_jobs(company_id, doc_type_id)",
        ]
        
        with engine.connect() as conn:
            for index_sql in indexes:
                try:
                    conn.execute(text(index_sql))
                    conn.commit()
                except SQLAlchemyError as e:
                    logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
        
        logger.info("âœ… æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ")
        engine.dispose()
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“ç´¢å¼•å¤±è´¥: {e}")
        return False

def insert_initial_data(database_url: str):
    """æ’å…¥åˆå§‹æ•°æ®"""
    try:
        logger.info("æ’å…¥åˆå§‹æ•°æ®...")
        engine = create_engine(database_url)
        
        from sqlalchemy.orm import sessionmaker
        Session = sessionmaker(bind=engine)
        session = Session()
        
        try:
            # åˆ›å»ºé»˜è®¤éƒ¨é—¨
            if not session.query(Department).filter_by(department_name="General").first():
                general_dept = Department(department_name="General")
                session.add(general_dept)
                logger.info("âœ… åˆ›å»ºé»˜è®¤éƒ¨é—¨: General")
            
            if not session.query(Department).filter_by(department_name="Finance").first():
                finance_dept = Department(department_name="Finance")
                session.add(finance_dept)
                logger.info("âœ… åˆ›å»ºéƒ¨é—¨: Finance")
                
            if not session.query(Department).filter_by(department_name="Operations").first():
                ops_dept = Department(department_name="Operations")
                session.add(ops_dept)
                logger.info("âœ… åˆ›å»ºéƒ¨é—¨: Operations")
            
            # åˆ›å»ºé»˜è®¤å…¬å¸
            if not session.query(Company).filter_by(company_code="DEFAULT").first():
                default_company = Company(
                    company_name="Default Company",
                    company_code="DEFAULT",
                    active=True
                )
                session.add(default_company)
                logger.info("âœ… åˆ›å»ºé»˜è®¤å…¬å¸: Default Company")
            
            if not session.query(Company).filter_by(company_code="hana").first():
                hana_company = Company(
                    company_name="Hana Company",
                    company_code="hana", 
                    active=True
                )
                session.add(hana_company)
                logger.info("âœ… åˆ›å»ºå…¬å¸: Hana Company")
            
            # åˆ›å»ºé»˜è®¤æ–‡æ¡£ç±»å‹
            document_types = [
                {
                    "type_name": "Invoice",
                    "type_code": "invoice",
                    "description": "Invoice documents for processing"
                },
                {
                    "type_name": "Finance HKBN Billing",
                    "type_code": "[Finance]_hkbn_billing",
                    "description": "HKBN billing documents"
                },
                {
                    "type_name": "MTR Invoice",
                    "type_code": "mtr_invoice", 
                    "description": "MTR invoice documents"
                },
                {
                    "type_name": "Assembly Built",
                    "type_code": "assembly_built",
                    "description": "Assembly built documents"
                }
            ]
            
            for doc_type_data in document_types:
                if not session.query(DocumentType).filter_by(type_code=doc_type_data["type_code"]).first():
                    doc_type = DocumentType(**doc_type_data)
                    session.add(doc_type)
                    logger.info(f"âœ… åˆ›å»ºæ–‡æ¡£ç±»å‹: {doc_type_data['type_name']}")
            
            session.commit()
            logger.info("âœ… åˆå§‹æ•°æ®æ’å…¥å®Œæˆ")
            
        except Exception as e:
            session.rollback()
            logger.error(f"âŒ æ’å…¥åˆå§‹æ•°æ®å¤±è´¥: {e}")
            return False
        finally:
            session.close()
            
        engine.dispose()
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ’å…¥åˆå§‹æ•°æ®å¤±è´¥: {e}")
        return False

def verify_database_setup(database_url: str):
    """éªŒè¯æ•°æ®åº“è®¾ç½®"""
    try:
        logger.info("éªŒè¯æ•°æ®åº“è®¾ç½®...")
        engine = create_engine(database_url)
        
        from sqlalchemy.orm import sessionmaker
        Session = sessionmaker(bind=engine)
        session = Session()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        tables_to_check = [
            (Company, "companies"),
            (DocumentType, "document_types"), 
            (ProcessingJob, "processing_jobs"),
            (BatchJob, "batch_jobs"),
            (User, "users"),
            (Department, "departments")
        ]
        
        for model, table_name in tables_to_check:
            try:
                count = session.query(model).count()
                logger.info(f"âœ… è¡¨ {table_name}: {count} æ¡è®°å½•")
            except Exception as e:
                logger.error(f"âŒ è¡¨ {table_name} æ£€æŸ¥å¤±è´¥: {e}")
                return False
        
        session.close()
        engine.dispose()
        logger.info("âœ… æ•°æ®åº“éªŒè¯å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–...")
    
    try:
        # è·å–æ•°æ®åº“URL
        database_url = get_database_url()
        logger.info(f"æ•°æ®åº“URL: {database_url.split('@')[1] if '@' in database_url else 'localhost'}")
        
        # ç­‰å¾…æ•°æ®åº“å¯ç”¨
        if not wait_for_database(database_url):
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œé€€å‡ºåˆå§‹åŒ–")
            sys.exit(1)
        
        # åˆ›å»ºæ•°æ®åº“è¡¨
        if not create_database_tables(database_url):
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥ï¼Œé€€å‡ºåˆå§‹åŒ–") 
            sys.exit(1)
        
        # æ·»åŠ çº¦æŸ
        if not add_check_constraints(database_url):
            logger.warning("âš ï¸ æ·»åŠ çº¦æŸå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ")
        
        # åˆ›å»ºç´¢å¼•
        if not create_indexes(database_url):
            logger.warning("âš ï¸ åˆ›å»ºç´¢å¼•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ")
        
        # æ’å…¥åˆå§‹æ•°æ®
        if not insert_initial_data(database_url):
            logger.error("âŒ æ’å…¥åˆå§‹æ•°æ®å¤±è´¥ï¼Œé€€å‡ºåˆå§‹åŒ–")
            sys.exit(1)
        
        # éªŒè¯æ•°æ®åº“è®¾ç½®
        if not verify_database_setup(database_url):
            logger.error("âŒ æ•°æ®åº“éªŒè¯å¤±è´¥ï¼Œé€€å‡ºåˆå§‹åŒ–")
            sys.exit(1)
        
        logger.info("ğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()